#!/usr/bin/env python3
"""
test_models.py - Script para probar todos los modelos y funcionalidades

Ejecutar para verificar que todo funciona correctamente.
"""

import asyncio
import time
import json
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Textos de prueba
TEST_TEXTS = {
    "ciencias": """
    La fotos√≠ntesis es el proceso biol√≥gico m√°s importante para la vida en la Tierra. 
    Las plantas utilizan la energ√≠a solar para convertir di√≥xido de carbono y agua en glucosa y ox√≠geno.
    Este proceso ocurre en los cloroplastos, espec√≠ficamente en los tilacoides donde se encuentra la clorofila.
    La fotos√≠ntesis consta de dos fases principales: las reacciones dependientes de luz y el ciclo de Calvin.
    Durante las reacciones de luz, se produce ATP y NADPH, mientras que en el ciclo de Calvin se fija el CO2.
    """,
    
    "historia": """
    La Revoluci√≥n Industrial comenz√≥ en Inglaterra a finales del siglo XVIII y transform√≥ completamente la sociedad.
    La invenci√≥n de la m√°quina de vapor por James Watt en 1769 revolucion√≥ el transporte y la producci√≥n.
    Las f√°bricas textiles fueron las primeras en adoptar la mecanizaci√≥n, especialmente en Manchester.
    La construcci√≥n de ferrocarriles conect√≥ ciudades y facilit√≥ el comercio de materias primas.
    Esta revoluci√≥n cambi√≥ las estructuras sociales, creando una nueva clase trabajadora urbana.
    """,
    
    "tecnologia": """
    La inteligencia artificial ha evolucionado dram√°ticamente en las √∫ltimas d√©cadas.
    Los algoritmos de machine learning permiten a las m√°quinas aprender patrones de datos.
    Las redes neuronales artificiales se inspiran en el funcionamiento del cerebro humano.
    El deep learning utiliza m√∫ltiples capas para procesar informaci√≥n compleja.
    Aplicaciones como el reconocimiento de voz y la visi√≥n por computadora son ya realidad.
    """
}

async def test_summary_generation():
    """Probar generaci√≥n de res√∫menes"""
    logger.info("üìù PROBANDO: Generaci√≥n de res√∫menes")
    
    try:
        from app.services.ai_service import AIService
        ai_service = AIService()
        
        results = {}
        
        for topic, text in TEST_TEXTS.items():
            logger.info(f"   Procesando: {topic}")
            
            start_time = time.time()
            result = await ai_service.generate_summary(text, "medium")
            end_time = time.time()
            
            if result["success"]:
                logger.info(f"   ‚úÖ {topic}: {end_time - start_time:.2f}s")
                results[topic] = {
                    "success": True,
                    "time": end_time - start_time,
                    "summary_length": len(result["summary"]),
                    "summary_preview": result["summary"][:100] + "..."
                }
            else:
                logger.error(f"   ‚ùå {topic}: {result.get('error', 'Error desconocido')}")
                results[topic] = {"success": False, "error": result.get("error")}
        
        return results
        
    except Exception as e:
        logger.error(f"Error en test de res√∫menes: {e}")
        return {"error": str(e)}

async def test_quiz_generation():
    """Probar generaci√≥n de quizzes"""
    logger.info("‚ùì PROBANDO: Generaci√≥n de quizzes")
    
    try:
        from app.services.ai_service import AIService
        ai_service = AIService()
        
        results = {}
        
        for topic, text in TEST_TEXTS.items():
            logger.info(f"   Procesando: {topic}")
            
            # Extraer conceptos clave b√°sicos
            concepts = text.split()[:5]  # Primeras 5 palabras como conceptos
            
            start_time = time.time()
            result = await ai_service.generate_quiz(text, concepts, 3, "medium")
            end_time = time.time()
            
            if result["success"] and len(result["questions"]) > 0:
                logger.info(f"   ‚úÖ {topic}: {len(result['questions'])} preguntas en {end_time - start_time:.2f}s")
                results[topic] = {
                    "success": True,
                    "time": end_time - start_time,
                    "question_count": len(result["questions"]),
                    "first_question": result["questions"][0]["question"] if result["questions"] else "N/A"
                }
            else:
                logger.error(f"   ‚ùå {topic}: {result.get('error', 'Error desconocido')}")
                results[topic] = {"success": False, "error": result.get("error")}
        
        return results
        
    except Exception as e:
        logger.error(f"Error en test de quizzes: {e}")
        return {"error": str(e)}

async def test_feedback_generation():
    """Probar generaci√≥n de retroalimentaci√≥n"""
    logger.info("üí¨ PROBANDO: Generaci√≥n de feedback")
    
    try:
        from app.services.ai_service import AIService
        ai_service = AIService()
        
        # Casos de prueba con diferentes puntuaciones
        test_cases = [
            {"score": 5, "total": 5, "concepts": ["fotos√≠ntesis", "clorofila"]},
            {"score": 3, "total": 5, "concepts": ["revoluci√≥n", "industrial"]},
            {"score": 1, "total": 5, "concepts": ["inteligencia", "artificial"]}
        ]
        
        results = {}
        
        for i, case in enumerate(test_cases):
            logger.info(f"   Caso {i+1}: {case['score']}/{case['total']}")
            
            start_time = time.time()
            feedback = await ai_service.generate_feedback(
                case["score"], 
                case["total"], 
                [], 
                case["concepts"]
            )
            end_time = time.time()
            
            logger.info(f"   ‚úÖ Feedback generado en {end_time - start_time:.2f}s")
            results[f"case_{i+1}"] = {
                "score": f"{case['score']}/{case['total']}",
                "time": end_time - start_time,
                "feedback_length": len(feedback),
                "feedback_preview": feedback[:100] + "..."
            }
        
        return results
        
    except Exception as e:
        logger.error(f"Error en test de feedback: {e}")
        return {"error": str(e)}

def test_model_loading():
    """Probar carga de modelos"""
    logger.info("ü§ñ PROBANDO: Carga de modelos")
    
    try:
        start_time = time.time()
        from app.services.ai_service import AIService
        ai_service = AIService()
        end_time = time.time()
        
        logger.info(f"   ‚úÖ Modelos cargados en {end_time - start_time:.2f}s")
        
        # Verificar que los modelos est√©n cargados
        has_summarizer = hasattr(ai_service, 'summarizer') and ai_service.summarizer is not None
        has_t5 = hasattr(ai_service, 't5_model') and ai_service.t5_model is not None
        has_classifier = hasattr(ai_service, 'classifier') and ai_service.classifier is not None
        
        return {
            "loading_time": end_time - start_time,
            "summarizer_loaded": has_summarizer,
            "t5_loaded": has_t5,
            "classifier_loaded": has_classifier,
            "device": ai_service.device if hasattr(ai_service, 'device') else "unknown"
        }
        
    except Exception as e:
        logger.error(f"Error cargando modelos: {e}")
        return {"error": str(e)}

def check_model_cache():
    """Verificar cach√© de modelos"""
    logger.info("üíæ VERIFICANDO: Cach√© de modelos")
    
    cache_dir = Path("model_cache")
    if not cache_dir.exists():
        logger.warning("   ‚ö†Ô∏è Directorio model_cache no existe")
        return {"cache_exists": False}
    
    # Calcular tama√±o del cach√©
    total_size = 0
    file_count = 0
    
    for file_path in cache_dir.rglob("*"):
        if file_path.is_file():
            total_size += file_path.stat().st_size
            file_count += 1
    
    size_mb = total_size / (1024 * 1024)
    logger.info(f"   üìä Cach√©: {file_count} archivos, {size_mb:.1f} MB")
    
    return {
        "cache_exists": True,
        "file_count": file_count,
        "size_mb": round(size_mb, 1),
        "path": str(cache_dir.absolute())
    }

def check_dependencies():
    """Verificar dependencias cr√≠ticas"""
    logger.info("üì¶ VERIFICANDO: Dependencias")
    
    dependencies = {
        "torch": "PyTorch",
        "transformers": "Hugging Face Transformers",
        "accelerate": "Accelerate",
        "sentence_transformers": "Sentence Transformers"
    }
    
    results = {}
    
    for module, name in dependencies.items():
        try:
            imported_module = __import__(module)
            version = getattr(imported_module, '__version__', 'unknown')
            logger.info(f"   ‚úÖ {name}: {version}")
            results[module] = {"installed": True, "version": version}
        except ImportError:
            logger.error(f"   ‚ùå {name}: No instalado")
            results[module] = {"installed": False}
    
    # Verificar GPU
    try:
        import torch
        gpu_available = torch.cuda.is_available()
        if gpu_available:
            gpu_name = torch.cuda.get_device_name(0)
            logger.info(f"   üéÆ GPU: {gpu_name}")
            results["gpu"] = {"available": True, "name": gpu_name}
        else:
            logger.info("   üíª GPU: No disponible (usando CPU)")
            results["gpu"] = {"available": False}
    except:
        results["gpu"] = {"available": False, "error": "No se pudo verificar"}
    
    return results

async def run_full_test():
    """Ejecutar todos los tests"""
    logger.info("üöÄ INICIANDO TESTS COMPLETOS")
    logger.info("=" * 60)
    
    results = {}
    
    # 1. Verificar dependencias
    results["dependencies"] = check_dependencies()
    
    # 2. Verificar cach√©
    results["model_cache"] = check_model_cache()
    
    # 3. Probar carga de modelos
    results["model_loading"] = test_model_loading()
    
    # 4. Probar res√∫menes
    results["summary_generation"] = await test_summary_generation()
    
    # 5. Probar quizzes
    results["quiz_generation"] = await test_quiz_generation()
    
    # 6. Probar feedback
    results["feedback_generation"] = await test_feedback_generation()
    
    return results

def generate_report(results):
    """Generar reporte de resultados"""
    logger.info("\n" + "=" * 60)
    logger.info("üìä REPORTE DE RESULTADOS")
    logger.info("=" * 60)
    
    # Guardar resultados en JSON
    report_file = Path("test_results.json")
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
    
    logger.info(f"üíæ Reporte completo guardado en: {report_file}")
    
    # Resumen ejecutivo
    total_tests = 0
    passed_tests = 0
    
    for category, data in results.items():
        if isinstance(data, dict):
            if category == "dependencies":
                for dep, info in data.items():
                    if dep != "gpu":
                        total_tests += 1
                        if info.get("installed", False):
                            passed_tests += 1
            elif category in ["summary_generation", "quiz_generation"]:
                if "error" not in data:
                    for topic, info in data.items():
                        total_tests += 1
                        if info.get("success", False):
                            passed_tests += 1
    
    success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0
    
    logger.info(f"\nüéØ RESUMEN:")
    logger.info(f"   Tests ejecutados: {total_tests}")
    logger.info(f"   Tests exitosos: {passed_tests}")
    logger.info(f"   Tasa de √©xito: {success_rate:.1f}%")
    
    if success_rate >= 90:
        logger.info("   üéâ ¬°Excelente! Todo est√° funcionando correctamente")
    elif success_rate >= 70:
        logger.info("   ‚ö†Ô∏è Hay algunos problemas menores")
    else:
        logger.info("   ‚ùå Se detectaron problemas importantes")
    
    logger.info(f"\nüìÅ Revisa {report_file} para detalles completos")

async def main():
    """Funci√≥n principal"""
    start_time = time.time()
    
    try:
        results = await run_full_test()
        generate_report(results)
        
        end_time = time.time()
        logger.info(f"\n‚è±Ô∏è Tests completados en {end_time - start_time:.2f} segundos")
        
    except Exception as e:
        logger.error(f"‚ùå Error ejecutando tests: {e}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit_code = asyncio.run(main())