# cleanup_for_git.py - Script para limpiar archivos antes de Git
"""
Script para limpiar archivos innecesarios antes de hacer commit
"""

import os
import shutil
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_folder_size(folder_path):
    """Calcula el tama√±o de una carpeta en MB"""
    total_size = 0
    try:
        for dirpath, dirnames, filenames in os.walk(folder_path):
            for f in filenames:
                fp = os.path.join(dirpath, f)
                if os.path.exists(fp):
                    total_size += os.path.getsize(fp)
    except:
        return 0
    return total_size / (1024 * 1024)  # Convertir a MB

def cleanup_large_files():
    """Limpia archivos grandes que no deben estar en Git"""
    
    print("üßπ LIMPIANDO ARCHIVOS PARA GIT")
    print("=" * 50)
    
    # Carpetas a limpiar (GRANDES)
    large_folders = [
        "models/fine_tuned",
        "model_cache", 
        ".cache",
        "checkpoints",
        "runs",
        "outputs",
        "wandb",
        "data/datasets"
    ]
    
    # Archivos a limpiar
    files_to_clean = [
        "training.log",
        "*.log",
        "GUIA_MODELOS_FINE_TUNED.md",  # Se regenera autom√°ticamente
        "validate_fine_tuned_models.py",  # Se regenera autom√°ticamente
        "diagnose_model_modules.py",
        "install_fine_tuning.sh",
        "quick_start_fine_tuning.sh"
    ]
    
    total_freed = 0
    
    # Limpiar carpetas grandes
    for folder in large_folders:
        if os.path.exists(folder):
            size_mb = get_folder_size(folder)
            try:
                if folder == "models/fine_tuned":
                    # Mantener solo model_config.json
                    config_file = os.path.join(folder, "model_config.json")
                    if os.path.exists(config_file):
                        # Hacer backup del config
                        shutil.copy2(config_file, "model_config_backup.json")
                    
                    shutil.rmtree(folder)
                    os.makedirs(folder, exist_ok=True)
                    
                    # Restaurar config
                    if os.path.exists("model_config_backup.json"):
                        shutil.move("model_config_backup.json", config_file)
                        print(f"   ‚úÖ {folder}/ limpiado (guardado model_config.json)")
                    else:
                        print(f"   ‚úÖ {folder}/ limpiado completamente")
                else:
                    shutil.rmtree(folder)
                    print(f"   ‚úÖ {folder}/ eliminado")
                
                total_freed += size_mb
                print(f"      Liberados: {size_mb:.1f} MB")
                
            except Exception as e:
                print(f"   ‚ö†Ô∏è No se pudo limpiar {folder}: {e}")
    
    # Limpiar archivos espec√≠ficos
    for file_pattern in files_to_clean:
        if "*" in file_pattern:
            # Manejar patrones con wildcard
            import glob
            files = glob.glob(file_pattern)
            for file in files:
                try:
                    os.remove(file)
                    print(f"   ‚úÖ {file} eliminado")
                except:
                    pass
        else:
            if os.path.exists(file_pattern):
                try:
                    os.remove(file_pattern)
                    print(f"   ‚úÖ {file_pattern} eliminado")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è No se pudo eliminar {file_pattern}: {e}")
    
    print(f"\nüìä TOTAL LIBERADO: {total_freed:.1f} MB")
    print("\nüìã ARCHIVOS IMPORTANTES MANTENIDOS:")
    print("   ‚úÖ training/ (c√≥digo de fine-tuning)")
    print("   ‚úÖ app/services/enhanced_ai_service.py")
    print("   ‚úÖ main_training.py")
    print("   ‚úÖ integrate_fine_tuned_models.py")
    print("   ‚úÖ requirements_fine_tuning.txt")
    print("   ‚úÖ models/fine_tuned/model_config.json")

def show_git_status():
    """Muestra qu√© archivos est√°n en Git"""
    print("\nüìÅ ARCHIVOS DE FINE-TUNING PARA GIT:")
    print("=" * 50)
    
    important_files = [
        "training/__init__.py",
        "training/lora_trainer.py", 
        "training/data_preparation.py",
        "main_training.py",
        "integrate_fine_tuned_models.py",
        "app/services/enhanced_ai_service.py",
        "requirements_fine_tuning.txt",
        "models/fine_tuned/model_config.json"
    ]
    
    for file in important_files:
        if os.path.exists(file):
            size_kb = os.path.getsize(file) / 1024
            print(f"   ‚úÖ {file} ({size_kb:.1f} KB)")
        else:
            print(f"   ‚ùå {file} - FALTANTE")

def create_gitkeep_files():
    """Crea archivos .gitkeep para mantener estructura de carpetas"""
    folders_to_keep = [
        "models/fine_tuned",
        "uploads",
        "temp"
    ]
    
    for folder in folders_to_keep:
        os.makedirs(folder, exist_ok=True)
        gitkeep_path = os.path.join(folder, ".gitkeep")
        if not os.path.exists(gitkeep_path):
            with open(gitkeep_path, "w") as f:
                f.write("# Mantener esta carpeta en Git\n")
            print(f"   ‚úÖ Creado {gitkeep_path}")

def main():
    """Funci√≥n principal"""
    cleanup_large_files()
    create_gitkeep_files()
    show_git_status()
    
    print("\nüöÄ COMANDOS RECOMENDADOS PARA GIT:")
    print("=" * 50)
    print("git add .")
    print("git commit -m 'feat: Implementar fine-tuning con LoRA para IA educativa'")
    print("git push")
    
    print("\nüìù NOTA: Los modelos fine-tuned NO se suben a Git")
    print("   Para compartir modelos, usar Hugging Face Hub o almacenamiento externo")

if __name__ == "__main__":
    main()