# IA Educativa Backend - VersiÃ³n 100% Gratuita

Backend FastAPI para aplicaciÃ³n de contenido educativo con IA generativa **completamente gratuita**.

## ğŸ‰ Modelos Gratuitos Utilizados

- **ResÃºmenes**: BART (facebook/bart-large-cnn)
- **Quiz Generator**: T5 (google/flan-t5-base) 
- **AnÃ¡lisis**: RoBERTa (cardiffnlp/twitter-roberta-base-sentiment-latest)
- **RetroalimentaciÃ³n**: T5 (google/flan-t5-base)

## âœ¨ CaracterÃ­sticas

- ğŸ“„ Procesamiento de archivos PDF y texto
- ğŸ¤– GeneraciÃ³n de resÃºmenes con BART (sin costo)
- ğŸ“Š AnÃ¡lisis de conceptos clave con Transformers
- â“ GeneraciÃ³n automÃ¡tica de quizzes con T5
- ğŸ“ˆ RetroalimentaciÃ³n pedagÃ³gica personalizada
- ğŸ”’ API segura con validaciÃ³n de datos
- ğŸ’° **100% GRATUITO - Sin APIs de pago**

## ğŸš€ InstalaciÃ³n RÃ¡pida

1. **Instalar dependencias**:
```bash
pip install -r requirements.txt
```

2. **Instalar modelo de spaCy en espaÃ±ol**:
```bash
python -m spacy download es_core_news_sm
```

3. **Configurar variables de entorno** (.env):
```env
SECRET_KEY=tu_secret_key_seguro
ENVIRONMENT=development
AI_USE_GPU=true
AI_MODEL_SIZE=base
```

4. **Ejecutar servidor**:
```bash
uvicorn app.main:app --reload
```

## ğŸ“‹ API Endpoints

### Upload
- `POST /api/v1/upload/upload-file` - Subir archivo PDF/texto
- `POST /api/v1/upload/upload-text` - Enviar texto directo

### Summary
- `POST /api/v1/summary/generate-summary` - Generar resumen (BART)
- `POST /api/v1/summary/generate-visualization` - Crear visualizaciones

### Quiz
- `POST /api/v1/quiz/generate-quiz` - Generar quiz (T5)
- `POST /api/v1/quiz/submit-quiz` - Enviar respuestas
- `GET /api/v1/quiz/quiz-session/{session_id}` - Info de sesiÃ³n

## ğŸ›  TecnologÃ­as

- **FastAPI** - Framework web
- **BART** - GeneraciÃ³n de resÃºmenes (Facebook AI)
- **T5** - GeneraciÃ³n de preguntas (Google)
- **RoBERTa** - AnÃ¡lisis de sentimientos (Cardiff NLP)
- **Transformers** - Biblioteca de Hugging Face
- **PyTorch** - Framework de deep learning
- **spaCy** - Procesamiento de lenguaje natural
- **PyPDF2** - Procesamiento de PDFs

## ğŸ¯ Ventajas de esta VersiÃ³n

| CaracterÃ­stica | Antes (OpenAI) | Ahora (Gratuito) |
|---|---|---|
| **Costo** | $0.002/1K tokens | âœ… $0 - Totalmente gratis |
| **LÃ­mites** | Rate limits | âœ… Sin lÃ­mites |
| **Privacidad** | Datos enviados a OpenAI | âœ… Todo local |
| **Latencia** | Depende de API | âœ… Procesamiento local |
| **Dependencias** | Internet requerido | âœ… Funciona offline |

## ğŸ“Š Rendimiento

- **ResÃºmenes**: BART genera resÃºmenes de alta calidad comparables a GPT-3.5
- **Quiz**: T5 crea preguntas coherentes y educativas
- **Velocidad**: ~2-5 segundos por operaciÃ³n (con GPU)
- **Memoria**: ~2GB RAM mÃ­nimo, 4GB recomendado

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Para usar GPU (recomendado):
```bash
# Instalar PyTorch con CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Para modo CPU Ãºnicamente:
```env
AI_USE_GPU=false
AI_MODEL_SIZE=small
```

## ğŸ³ Docker (Opcional)

```dockerfile
FROM python:3.9
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

## ğŸ“ Estructura del Proyecto

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py              # AplicaciÃ³n principal
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py        # ConfiguraciÃ³n (sin OpenAI)
â”‚   â”‚   â””â”€â”€ security.py      # Seguridad
â”‚   â”œâ”€â”€ models/              # Modelos de datos
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ ai_service.py    # BART + T5 + Transformers
â”‚   â”‚   â”œâ”€â”€ nlp_service.py   # spaCy + anÃ¡lisis
â”‚   â”‚   â”œâ”€â”€ pdf_processor.py # Procesamiento PDFs
â”‚   â”‚   â””â”€â”€ quiz_generator.py # GestiÃ³n de quizzes
â”‚   â”œâ”€â”€ api/routes/          # Endpoints
â”‚   â””â”€â”€ utils/               # Utilidades
â”œâ”€â”€ model_cache/             # CachÃ© de modelos descargados
â”œâ”€â”€ uploads/                 # Archivos subidos
â””â”€â”€ requirements.txt         # Dependencias actualizadas
```

## ğŸš€ MigraciÃ³n desde OpenAI

### Pasos para migrar:

1. **Actualizar requirements.txt** con las nuevas dependencias
2. **Reemplazar ai_service.py** con la versiÃ³n de modelos gratuitos
3. **Actualizar config.py** para remover OPENAI_API_KEY
4. **Ejecutar la primera vez** (descargarÃ¡ modelos automÃ¡ticamente):

```bash
python -c "from app.services.ai_service import AIService; AIService()"
```

## ğŸ’¾ Espacio en Disco

Los modelos requieren espacio de descarga inicial:

- **BART (resÃºmenes)**: ~1.6GB
- **T5-base (quiz)**: ~900MB  
- **RoBERTa (anÃ¡lisis)**: ~500MB
- **Total aproximado**: ~3GB

## âš¡ Optimizaciones

### Para hardware limitado:
```env
AI_MODEL_SIZE=small  # Usa modelos mÃ¡s pequeÃ±os
AI_USE_GPU=false     # Modo CPU Ãºnicamente
```

### Para mejor rendimiento:
```env
AI_MODEL_SIZE=large  # Modelos mÃ¡s grandes y precisos
AI_USE_GPU=true      # Usa GPU si estÃ¡ disponible
```

## ğŸ” ComparaciÃ³n de Modelos

| Modelo | TamaÃ±o | Calidad | Velocidad | Memoria |
|--------|--------|---------|-----------|---------|
| **T5-small** | 242MB | â­â­â­ | âš¡âš¡âš¡ | 1GB |
| **T5-base** | 892MB | â­â­â­â­ | âš¡âš¡ | 2GB |
| **BART-large** | 1.6GB | â­â­â­â­â­ | âš¡ | 4GB |

## ğŸ§ª Testing

```bash
# Probar el servicio de IA
python -m pytest tests/test_ai_service.py

# Probar endpoints
python -m pytest tests/test_endpoints.py

# Benchmark de rendimiento
python scripts/benchmark_models.py
```

## ğŸ”§ SoluciÃ³n de Problemas

### Error: "CUDA out of memory"
```env
AI_USE_GPU=false
AI_MODEL_SIZE=small
```

### Error: "Model not found"
```bash
# Limpiar cachÃ© y volver a descargar
rm -rf model_cache/
python -c "from app.services.ai_service import AIService; AIService()"
```

### Lentitud en CPU
```bash
# Instalar optimizaciones para CPU
pip install intel-extension-for-pytorch  # Para CPUs Intel
# o
pip install torch-audio --extra-index-url https://download.pytorch.org/whl/cpu
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

## ğŸ“ˆ Monitoreo

El sistema incluye logs detallados:

```bash
# Ver logs en tiempo real
tail -f app.log

# Buscar errores especÃ­ficos
grep "ERROR" app.log
```

## ğŸ†™ Actualizaciones Futuras

- [ ] IntegraciÃ³n con Stable Diffusion para generar imÃ¡genes
- [ ] Soporte para modelos Mistral y LLaMA 2
- [ ] Optimizaciones adicionales para ARM (Apple Silicon)
- [ ] Cache inteligente de resultados
- [ ] API de batch processing

## ğŸ“ Soporte

- **DocumentaciÃ³n**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/health  
- **Logs**: Revisar logs de la aplicaciÃ³n
- **Issues**: Crear issue en el repositorio

## ğŸ“„ Licencia

MIT License - Uso libre y gratuito