# app/services/enhanced_ai_service.py - VERSI√ìN FINAL MEJORADA PARA CUALQUIER TEXTO
import torch
import json
import logging
import os
import re
import random
from typing import Dict, Any, List, Optional
from transformers import (
    AutoTokenizer, AutoModelForSeq2SeqLM, T5ForConditionalGeneration,
    pipeline, BartForConditionalGeneration, BartTokenizer
)
from peft import PeftModel
from app.services.ai_service import AIService
from collections import Counter

logger = logging.getLogger(__name__)

class EnhancedAIService(AIService):
    """
    Servicio de IA mejorado con modelos fine-tuned y l√≥gica perfeccionada para cualquier tipo de texto
    """
    
    def __init__(self):
        # Llamar al constructor padre
        super().__init__()
        self.fine_tuned_models = {}
        self.model_config = None
        
        # Cargar modelos mejorados
        self._load_enhanced_models()
        
        # Patrones y plantillas universales
        self._setup_universal_patterns()
    
    def _setup_universal_patterns(self):
        """Configura patrones universales para diferentes tipos de texto"""
        self.text_patterns = {
            "historia": {
                "keywords": ["guerra", "batalla", "imperio", "revoluci√≥n", "siglo", "a√±o", "√©poca", "dinast√≠a"],
                "question_types": ["cronol√≥gico", "causal", "comparativo", "factual"],
                "summary_focus": ["fechas", "personajes", "eventos", "causas", "consecuencias"]
            },
            "ciencia": {
                "keywords": ["proceso", "m√©todo", "experimento", "hip√≥tesis", "teor√≠a", "ley", "f√≥rmula", "an√°lisis"],
                "question_types": ["conceptual", "procedimental", "aplicativo", "anal√≠tico"],
                "summary_focus": ["conceptos", "procesos", "aplicaciones", "caracter√≠sticas"]
            },
            "tecnolog√≠a": {
                "keywords": ["algoritmo", "sistema", "datos", "software", "hardware", "red", "c√≥digo", "digital"],
                "question_types": ["t√©cnico", "aplicativo", "comparativo", "funcional"],
                "summary_focus": ["funcionalidades", "aplicaciones", "ventajas", "componentes"]
            },
            "literatura": {
                "keywords": ["personaje", "narrador", "trama", "estilo", "g√©nero", "obra", "autor", "movimiento"],
                "question_types": ["interpretativo", "anal√≠tico", "contextual", "estil√≠stico"],
                "summary_focus": ["temas", "personajes", "estilo", "contexto"]
            },
            "economia": {
                "keywords": ["mercado", "precio", "oferta", "demanda", "inversi√≥n", "capital", "producto", "empresa"],
                "question_types": ["anal√≠tico", "aplicativo", "comparativo", "predictivo"],
                "summary_focus": ["conceptos", "relaciones", "factores", "impacto"]
            },
            "medicina": {
                "keywords": ["s√≠ntoma", "diagn√≥stico", "tratamiento", "enfermedad", "paciente", "terapia", "prevenci√≥n"],
                "question_types": ["diagn√≥stico", "terap√©utico", "preventivo", "factual"],
                "summary_focus": ["s√≠ntomas", "causas", "tratamientos", "prevenci√≥n"]
            },
            "filosof√≠a": {
                "keywords": ["concepto", "idea", "pensamiento", "raz√≥n", "√©tica", "moral", "existencia", "conocimiento"],
                "question_types": ["conceptual", "cr√≠tico", "comparativo", "reflexivo"],
                "summary_focus": ["conceptos", "argumentos", "posturas", "implicaciones"]
            }
        }
    
    def _load_enhanced_models(self):
        """Carga modelos mejorados (fine-tuned si existen, base optimizado si no)"""
        config_path = "./models/fine_tuned/model_config.json"
        
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    self.model_config = json.load(f)
                self._load_fine_tuned_models()
                logger.info("Modelos fine-tuned cargados exitosamente")
            except Exception as e:
                logger.warning(f"Error cargando modelos fine-tuned: {e}")
                self._setup_enhanced_base_models()
        else:
            logger.info("No se encontraron modelos fine-tuned, usando modelos base optimizados")
            self._setup_enhanced_base_models()
    
    def _setup_enhanced_base_models(self):
        """Configura modelos base optimizados"""
        try:
            # Usar modelos base pero con configuraciones optimizadas
            logger.info("Configurando modelos base optimizados...")
            
            # Para res√∫menes: BART optimizado
            self.enhanced_summarizer = pipeline(
                "summarization",
                model="facebook/bart-large-cnn",
                device=0 if self.device == "cuda" else -1,
                max_length=300,
                min_length=100,
                do_sample=True,
                temperature=0.7
            )
            
            # Para generaci√≥n de texto: T5 optimizado
            self.enhanced_generator = pipeline(
                "text2text-generation",
                model="google/flan-t5-base",
                device=0 if self.device == "cuda" else -1,
                max_length=150,
                do_sample=True,
                temperature=0.8
            )
            
            logger.info("Modelos base optimizados configurados")
            
        except Exception as e:
            logger.error(f"Error configurando modelos base: {e}")
    
    def _load_fine_tuned_models(self):
        """Carga los modelos fine-tuned si est√°n disponibles"""
        try:
            models = self.model_config.get("models", {})
            
            for model_name, config in models.items():
                lora_path = config.get("lora_path")
                if os.path.exists(lora_path):
                    try:
                        base_model_name = config["base_model"]
                        
                        if "bart" in base_model_name.lower():
                            base_model = BartForConditionalGeneration.from_pretrained(base_model_name)
                            tokenizer = BartTokenizer.from_pretrained(base_model_name)
                        else:
                            base_model = T5ForConditionalGeneration.from_pretrained(base_model_name)
                            tokenizer = AutoTokenizer.from_pretrained(base_model_name)
                        
                        fine_tuned_model = PeftModel.from_pretrained(base_model, lora_path).to(self.device)
                        
                        self.fine_tuned_models[model_name] = {
                            "model": fine_tuned_model,
                            "tokenizer": tokenizer
                        }
                        
                        logger.info(f"Modelo fine-tuned cargado: {model_name}")
                        
                    except Exception as e:
                        logger.warning(f"Error cargando modelo {model_name}: {e}")
                        
        except Exception as e:
            logger.error(f"Error general cargando modelos fine-tuned: {e}")
    
    def _detect_text_type(self, text: str) -> str:
        """Detecta el tipo de texto basado en contenido y keywords"""
        text_lower = text.lower()
        
        # Contar keywords por categor√≠a
        category_scores = {}
        
        for category, patterns in self.text_patterns.items():
            score = 0
            for keyword in patterns["keywords"]:
                score += text_lower.count(keyword)
            category_scores[category] = score
        
        # Detectores espec√≠ficos adicionales
        if any(word in text_lower for word in ["guerra", "batalla", "siglo", "a√±o", "emperador", "rey"]):
            category_scores["historia"] += 5
        
        if any(word in text_lower for word in ["c√©lula", "gen", "prote√≠na", "bacteria", "virus"]):
            category_scores["ciencia"] += 5
        
        if any(word in text_lower for word in ["algoritmo", "software", "programa", "c√≥digo", "datos"]):
            category_scores["tecnolog√≠a"] += 5
        
        if any(word in text_lower for word in ["mercado", "econ√≥mico", "precio", "empresa", "negocio"]):
            category_scores["economia"] += 5
        
        # Retornar categor√≠a con mayor score o "general"
        best_category = max(category_scores, key=category_scores.get)
        return best_category if category_scores[best_category] > 0 else "general"
    
    async def generate_summary(self, text: str, length: str = "medium") -> Dict[str, Any]:
        """Genera resumen inteligente adaptado al tipo de texto"""
        try:
            # Detectar tipo de texto
            text_type = self._detect_text_type(text)
            logger.info(f"Tipo de texto detectado: {text_type}")
            
            # Usar modelo fine-tuned si est√° disponible
            if "summarizer" in self.fine_tuned_models:
                return await self._generate_fine_tuned_summary(text, length, text_type)
            else:
                return await self._generate_enhanced_summary(text, length, text_type)
                
        except Exception as e:
            logger.error(f"Error generando resumen: {e}")
            return await super().generate_summary(text, length)
    
    async def _generate_fine_tuned_summary(self, text: str, length: str, text_type: str) -> Dict[str, Any]:
        """Genera resumen con modelo fine-tuned"""
        try:
            model_info = self.fine_tuned_models["summarizer"]
            model = model_info["model"]
            tokenizer = model_info["tokenizer"]
            
            # Crear prompt especializado seg√∫n tipo de texto
            prompt = self._create_specialized_prompt(text, text_type, "summary")
            
            # Configurar longitud
            length_config = {
                "short": {"max_length": 150, "min_length": 50},
                "medium": {"max_length": 250, "min_length": 100},
                "long": {"max_length": 350, "min_length": 150}
            }
            config = length_config.get(length, length_config["medium"])
            
            # Tokenizar
            inputs = tokenizer(
                prompt,
                max_length=1024,
                truncation=True,
                padding=True,
                return_tensors="pt"
            ).to(self.device)
            
            # Generar
            with torch.no_grad():
                outputs = model.generate(
                    **inputs,
                    max_length=config["max_length"],
                    min_length=config["min_length"],
                    do_sample=True,
                    temperature=0.7,
                    top_p=0.95,
                    repetition_penalty=1.2,
                    no_repeat_ngram_size=3
                )
            
            # Decodificar y procesar
            raw_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)
            final_summary = self._create_structured_summary(raw_summary, text, text_type)
            
            return {
                "summary": final_summary,
                "success": True,
                "model_used": "fine_tuned_summarizer",
                "text_type": text_type
            }
            
        except Exception as e:
            logger.error(f"Error con modelo fine-tuned: {e}")
            return await self._generate_enhanced_summary(text, length, text_type)
    
    async def _generate_enhanced_summary(self, text: str, length: str, text_type: str) -> Dict[str, Any]:
        """Genera resumen mejorado con modelos base"""
        try:
            # Usar el modelo base optimizado
            if hasattr(self, 'enhanced_summarizer'):
                # Generar resumen base
                summary_result = self.enhanced_summarizer(
                    text[:1024],  # Limitar entrada
                    max_length=200 if length == "medium" else (150 if length == "short" else 250),
                    min_length=80 if length == "medium" else (50 if length == "short" else 120),
                    do_sample=True,
                    temperature=0.7
                )
                raw_summary = summary_result[0]['summary_text']
            else:
                # Fallback al m√©todo padre
                result = await super().generate_summary(text, length)
                raw_summary = result["summary"]
            
            # Crear resumen estructurado
            final_summary = self._create_structured_summary(raw_summary, text, text_type)
            
            return {
                "summary": final_summary,
                "success": True,
                "model_used": "enhanced_base_summarizer",
                "text_type": text_type
            }
            
        except Exception as e:
            logger.error(f"Error en resumen mejorado: {e}")
            return await super().generate_summary(text, length)
    
    def _create_specialized_prompt(self, text: str, text_type: str, task: str) -> str:
        """Crea prompts especializados seg√∫n tipo de texto y tarea"""
        
        if task == "summary":
            if text_type == "historia":
                return f"""Crea un resumen educativo de este texto hist√≥rico, destacando:
- Fechas y per√≠odos importantes
- Personajes clave y sus roles
- Eventos principales y su secuencia
- Causas y consecuencias

TEXTO: {text[:800]}

RESUMEN EDUCATIVO:"""

            elif text_type == "ciencia":
                return f"""Crea un resumen educativo de este texto cient√≠fico, destacando:
- Conceptos y principios fundamentales
- Procesos o m√©todos descritos
- Aplicaciones pr√°cticas
- Caracter√≠sticas importantes

TEXTO: {text[:800]}

RESUMEN EDUCATIVO:"""

            elif text_type == "tecnolog√≠a":
                return f"""Crea un resumen educativo de este texto tecnol√≥gico, destacando:
- Tecnolog√≠as y sistemas principales
- Funcionalidades y caracter√≠sticas
- Aplicaciones y usos
- Ventajas y beneficios

TEXTO: {text[:800]}

RESUMEN EDUCATIVO:"""

            else:
                return f"""Crea un resumen educativo estructurado de este texto:

TEXTO: {text[:800]}

RESUMEN EDUCATIVO:"""
        
        elif task == "question":
            return f"""Genera preguntas educativas de calidad sobre este texto de {text_type}:

TEXTO: {text[:600]}

Pregunta educativa:"""
        
        return text
    
    def _create_structured_summary(self, raw_summary: str, original_text: str, text_type: str) -> str:
        """Crea resumen estructurado seg√∫n el tipo de texto"""
        
        # Extraer informaci√≥n espec√≠fica del texto
        key_info = self._extract_specialized_info(original_text, text_type)
        
        # Crear estructura base
        structured_summary = "üìö **RESUMEN EDUCATIVO ESPECIALIZADO**\n\n"
        
        # Agregar tema principal
        structured_summary += f"üéØ **TEMA:** {key_info.get('topic', 'An√°lisis del contenido')}\n\n"
        
        # Agregar informaci√≥n espec√≠fica seg√∫n tipo
        if text_type == "historia" and key_info.get('dates'):
            structured_summary += f"üìÖ **CRONOLOG√çA:** {' ‚Üí '.join(key_info['dates'][:4])}\n\n"
        
        if key_info.get('key_concepts'):
            structured_summary += f"üîë **CONCEPTOS CLAVE:** {', '.join(key_info['key_concepts'][:5])}\n\n"
        
        if text_type == "historia" and key_info.get('people'):
            structured_summary += f"üë• **FIGURAS IMPORTANTES:** {', '.join(key_info['people'][:4])}\n\n"
        
        # Limpiar y agregar contenido principal
        clean_summary = self._clean_and_improve_summary(raw_summary)
        structured_summary += f"üìù **CONTENIDO PRINCIPAL:**\n{clean_summary}\n\n"
        
        # Agregar puntos clave espec√≠ficos
        key_points = self._generate_key_points(original_text, text_type)
        if key_points:
            structured_summary += f"üí° **PUNTOS CLAVE:**\n"
            for i, point in enumerate(key_points, 1):
                structured_summary += f"{i}. {point}\n"
        
        return structured_summary
    
    def _extract_specialized_info(self, text: str, text_type: str) -> Dict[str, Any]:
        """Extrae informaci√≥n especializada seg√∫n el tipo de texto"""
        info = {
            "topic": "el tema principal",
            "key_concepts": [],
            "dates": [],
            "people": [],
            "processes": [],
            "locations": []
        }
        
        if text_type == "historia":
            # Extraer fechas y a√±os
            dates = re.findall(r'\b((?:siglo\s+)?(?:XV{0,3}I{0,3}|I{1,3}V?|V|IX|IV|X{1,3})|(?:19|20)\d{2}|\d{1,2}\s+de\s+\w+\s+de\s+\d{4})\b', text, re.IGNORECASE)
            info["dates"] = list(set(dates))[:5]
            
            # Extraer nombres propios (posibles personajes hist√≥ricos)
            names = re.findall(r'\b[A-Z√Å√â√ç√ì√ö√ú√ë][a-z√°√©√≠√≥√∫√º√±]+(?:\s+[A-Z√Å√â√ç√ì√ö√ú√ë][a-z√°√©√≠√≥√∫√º√±]+){1,2}\b', text)
            info["people"] = list(set([name for name in names if len(name.split()) <= 3]))[:5]
            
            # Detectar tema hist√≥rico
            if "guerra mundial" in text.lower():
                info["topic"] = "Guerra Mundial"
            elif "revoluci√≥n" in text.lower():
                info["topic"] = "Revoluci√≥n Hist√≥rica"
            elif "imperio" in text.lower():
                info["topic"] = "Historia Imperial"
        
        elif text_type == "ciencia":
            # Extraer procesos cient√≠ficos
            processes = re.findall(r'\b\w*(?:ci√≥n|sis|oma|ema)\b', text, re.IGNORECASE)
            info["processes"] = list(set([p for p in processes if len(p) > 4]))[:5]
            
            # Detectar tema cient√≠fico
            if "fotos√≠ntesis" in text.lower():
                info["topic"] = "Fotos√≠ntesis"
            elif "c√©lula" in text.lower():
                info["topic"] = "Biolog√≠a Celular"
            elif "qu√≠mica" in text.lower():
                info["topic"] = "Procesos Qu√≠micos"
        
        elif text_type == "tecnolog√≠a":
            # Extraer t√©rminos t√©cnicos
            tech_terms = re.findall(r'\b(?:algoritmo|software|hardware|sistema|programa|aplicaci√≥n|tecnolog√≠a)\w*\b', text, re.IGNORECASE)
            info["processes"] = list(set(tech_terms))[:5]
            
            if "inteligencia artificial" in text.lower():
                info["topic"] = "Inteligencia Artificial"
            elif "programaci√≥n" in text.lower():
                info["topic"] = "Programaci√≥n y Desarrollo"
        
        # Extraer conceptos clave generales
        words = re.findall(r'\b[A-Z√Å√â√ç√ì√ö√ú√ë][a-z√°√©√≠√≥√∫√º√±]{3,}\b', text)
        word_freq = Counter(words)
        stop_words = {'Para', 'Esto', 'Todo', 'Cada', 'Debe', 'Puede', 'Ser√°', 'Est√°', 'Hace', 'Tiene'}
        concepts = [word for word, freq in word_freq.most_common(10) 
                   if word not in stop_words and freq > 1]
        info["key_concepts"] = concepts[:6]
        
        return info
    
    def _clean_and_improve_summary(self, summary: str) -> str:
        """Limpia y mejora el resumen generado"""
        # Eliminar errores comunes
        corrections = {
            "seguirra": "guerra",
            "eusu": "EEUU",
            "histororia": "historia",
            "teh": "the",
            "proces": "proceso"
        }
        
        clean_summary = summary
        for error, correction in corrections.items():
            clean_summary = clean_summary.replace(error, correction)
        
        # Mejorar estructura
        sentences = clean_summary.split('.')
        improved_sentences = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 10:
                # Capitalizar primera letra
                sentence = sentence[0].upper() + sentence[1:] if sentence else sentence
                improved_sentences.append(sentence)
        
        return '. '.join(improved_sentences) + '.'
    
    def _generate_key_points(self, text: str, text_type: str) -> List[str]:
        """Genera puntos clave espec√≠ficos seg√∫n el tipo de texto"""
        points = []
        
        if text_type == "historia":
            if "guerra mundial" in text.lower():
                points = [
                    "Conflicto global que transform√≥ el orden mundial",
                    "Involucr√≥ a m√∫ltiples naciones y continentes",
                    "Tuvo consecuencias pol√≠ticas, sociales y econ√≥micas duraderas"
                ]
            elif "revoluci√≥n" in text.lower():
                points = [
                    "Per√≠odo de cambios sociales y pol√≠ticos significativos",
                    "Transform√≥ las estructuras de poder existentes",
                    "Influy√≥ en el desarrollo hist√≥rico posterior"
                ]
        
        elif text_type == "ciencia":
            if "fotos√≠ntesis" in text.lower():
                points = [
                    "Proceso fundamental para la vida en la Tierra",
                    "Convierte la energ√≠a solar en energ√≠a qu√≠mica",
                    "Produce ox√≠geno esencial para la respiraci√≥n"
                ]
            else:
                points = [
                    "Conceptos cient√≠ficos basados en evidencia y m√©todo",
                    "Aplicaciones pr√°cticas en la vida cotidiana",
                    "Importancia para el avance del conocimiento"
                ]
        
        elif text_type == "tecnolog√≠a":
            points = [
                "Tecnolog√≠a que mejora la eficiencia y capacidades humanas",
                "Aplicaciones en m√∫ltiples sectores y disciplinas",
                "Evoluci√≥n constante y adaptaci√≥n a nuevas necesidades"
            ]
        
        # Puntos generales si no hay espec√≠ficos
        if not points:
            sentences = text.split('.')
            important_sentences = [s.strip() for s in sentences 
                                 if 40 < len(s.strip()) < 120 and 
                                 any(word in s.lower() for word in ['importante', 'principal', 'fundamental', 'clave'])]
            points = important_sentences[:3]
        
        return points[:3]
    
    async def generate_quiz(self, text: str, key_concepts: List[str], 
                          num_questions: int = 5, difficulty: str = "medium") -> Dict[str, Any]:
        """Genera quiz inteligente adaptado al tipo de texto"""
        try:
            # Detectar tipo de texto
            text_type = self._detect_text_type(text)
            logger.info(f"Generando quiz para texto tipo: {text_type}")
            
            # Usar modelo fine-tuned si est√° disponible
            if "question_generator" in self.fine_tuned_models:
                return await self._generate_fine_tuned_quiz(text, key_concepts, num_questions, difficulty, text_type)
            else:
                return await self._generate_enhanced_quiz(text, key_concepts, num_questions, difficulty, text_type)
                
        except Exception as e:
            logger.error(f"Error generando quiz: {e}")
            return await super().generate_quiz(text, key_concepts, num_questions, difficulty)
    
    async def _generate_enhanced_quiz(self, text: str, key_concepts: List[str], 
                                    num_questions: int, difficulty: str, text_type: str) -> Dict[str, Any]:
        """Genera quiz mejorado seg√∫n el tipo de texto"""
        try:
            questions = []
            
            # Extraer informaci√≥n especializada
            specialized_info = self._extract_specialized_info(text, text_type)
            
            # Crear preguntas espec√≠ficas por tipo de texto
            if text_type == "historia":
                questions = self._create_history_questions(text, specialized_info, num_questions, difficulty)
            elif text_type == "ciencia":
                questions = self._create_science_questions(text, specialized_info, num_questions, difficulty)
            elif text_type == "tecnolog√≠a":
                questions = self._create_tech_questions(text, specialized_info, num_questions, difficulty)
            else:
                questions = self._create_general_questions(text, key_concepts, num_questions, difficulty)
            
            # Completar con preguntas generales si es necesario
            while len(questions) < num_questions:
                additional_question = self._create_contextual_question(
                    len(questions) + 1, text, key_concepts, difficulty
                )
                questions.append(additional_question)
            
            return {
                "questions": questions[:num_questions],
                "success": True,
                "model_used": "enhanced_quiz_generator",
                "text_type": text_type
            }
            
        except Exception as e:
            logger.error(f"Error en quiz mejorado: {e}")
            return await super().generate_quiz(text, key_concepts, num_questions, difficulty)
    
    def _create_history_questions(self, text: str, info: Dict, num_questions: int, difficulty: str) -> List[Dict]:
        """Crea preguntas espec√≠ficas para textos hist√≥ricos"""
        questions = []
        
        # Preguntas sobre fechas y cronolog√≠a
        if info.get("dates") and len(questions) < num_questions:
            dates = info["dates"]
            question = {
                "id": len(questions) + 1,
                "question": "¬øCu√°l es el per√≠odo temporal principal abordado en el texto?",
                "options": [
                    f"Entre {dates[0]} y {dates[-1]}" if len(dates) > 1 else f"Durante {dates[0]}",
                    "Siglo XV",
                    "Era contempor√°nea",
                    "Prehistoria"
                ],
                "correct_answer": 0,
                "explanation": f"El texto se centra en el per√≠odo {dates[0]} - {dates[-1] if len(dates) > 1 else 'mencionado'}, como se indica en las fechas principales del contenido.",
                "difficulty": difficulty
            }
            questions.append(question)
        
        # Preguntas sobre personajes hist√≥ricos
        if info.get("people") and len(questions) < num_questions:
            people = info["people"]
            question = {
                "id": len(questions) + 1,
                "question": "¬øQui√©n es una figura hist√≥rica importante mencionada en el texto?",
                "options": [
                    people[0],
                    "Napole√≥n Bonaparte",
                    "Julio C√©sar",
                    "Cleopatra"
                ],
                "correct_answer": 0,
                "explanation": f"{people[0]} es mencionado en el texto como una figura relevante para los eventos hist√≥ricos descritos.",
                "difficulty": difficulty
            }
            questions.append(question)
        
        # Pregunta sobre causas y consecuencias
        if len(questions) < num_questions:
            question = {
                "id": len(questions) + 1,
                "question": "¬øCu√°l fue una de las principales consecuencias de los eventos descritos?",
                "options": [
                    "Transformaci√≥n del orden pol√≠tico y social",
                    "Desaparici√≥n completa de las instituciones",
                    "Vuelta al sistema feudal",
                    "Eliminaci√≥n de todas las fronteras"
                ],
                "correct_answer": 0,
                "explanation": "Los eventos hist√≥ricos descritos tuvieron como consecuencia principal la transformaci√≥n del orden pol√≠tico y social existente.",
                "difficulty": difficulty
            }
            questions.append(question)
        
        return questions
    
    def _create_science_questions(self, text: str, info: Dict, num_questions: int, difficulty: str) -> List[Dict]:
        """Crea preguntas espec√≠ficas para textos cient√≠ficos"""
        questions = []
        
        # Pregunta sobre procesos cient√≠ficos
        if len(questions) < num_questions:
            question = {
                "id": len(questions) + 1,
                "question": "¬øCu√°l es el proceso principal descrito en el texto?",
                "options": [
                    "El proceso cient√≠fico explicado en el contenido",
                    "Un proceso de manufactura industrial",
                    "Un proceso pol√≠tico",
                    "Un proceso puramente te√≥rico sin aplicaci√≥n"
                ],
                "correct_answer": 0,
                "explanation": "El texto describe un proceso cient√≠fico espec√≠fico con sus caracter√≠sticas y aplicaciones.",
                "difficulty": difficulty
            }
            questions.append(question)
        
        # Pregunta sobre aplicaciones
        if len(questions) < num_questions:
            question = {
                "id": len(questions) + 1,
                "question": "¬øCu√°l es la importancia pr√°ctica de lo descrito en el texto?",
                "options": [
                    "Tiene aplicaciones importantes en la vida cotidiana y la ciencia",
                    "Solo tiene valor te√≥rico",
                    "Es completamente obsoleto",
                    "Solo se aplica en laboratorios especializados"
                ],
                "correct_answer": 0,
                "explanation": "Los conceptos cient√≠ficos descritos tienen aplicaciones pr√°cticas relevantes para la comprensi√≥n y mejora de procesos naturales o tecnol√≥gicos.",
                "difficulty": difficulty
            }
            questions.append(question)
        
        # Pregunta sobre caracter√≠sticas
        if len(questions) < num_questions:
            question = {
                "id": len(questions) + 1,
                "question": "¬øQu√© caracter√≠sticas fundamentales se destacan en el contenido cient√≠fico?",
                "options": [
                    "M√©todos basados en evidencia y experimentaci√≥n",
                    "Creencias y tradiciones populares",
                    "Opiniones personales sin fundamento",
                    "Supersticiones y mitos antiguos"
                ],
                "correct_answer": 0,
                "explanation": "El contenido cient√≠fico se caracteriza por estar basado en m√©todos rigurosos, evidencia emp√≠rica y experimentaci√≥n controlada.",
                "difficulty": difficulty
            }
            questions.append(question)
        
        return questions
    
    def _create_tech_questions(self, text: str, info: Dict, num_questions: int, difficulty: str) -> List[Dict]:
        """Crea preguntas espec√≠ficas para textos tecnol√≥gicos"""
        questions = []
        
        # Pregunta sobre funcionalidad
        if len(questions) < num_questions:
            question = {
                "id": len(questions) + 1,
                "question": "¬øCu√°l es la principal funcionalidad de la tecnolog√≠a descrita?",
                "options": [
                    "Mejorar la eficiencia y capacidades en tareas espec√≠ficas",
                    "Reemplazar completamente el trabajo humano",
                    "Crear problemas tecnol√≥gicos adicionales",
                    "Funcionar solo en condiciones ideales"
                ],
                "correct_answer": 0,
                "explanation": "Las tecnolog√≠as descritas tienen como objetivo principal mejorar la eficiencia y ampliar las capacidades humanas en diversas tareas.",
                "difficulty": difficulty
            }
            questions.append(question)
        
        # Pregunta sobre aplicaciones
        if len(questions) < num_questions:
            question = {
                "id": len(questions) + 1,
                "question": "¬øEn qu√© √°mbitos se puede aplicar esta tecnolog√≠a?",
                "options": [
                    "En m√∫ltiples sectores y disciplinas",
                    "Solo en investigaci√≥n acad√©mica",
                    "√önicamente en empresas tecnol√≥gicas",
                    "Solo en el sector militar"
                ],
                "correct_answer": 0,
                "explanation": "La tecnolog√≠a descrita tiene aplicaciones vers√°tiles que se extienden a m√∫ltiples sectores y disciplinas.",
                "difficulty": difficulty
            }
            questions.append(question)
        
        return questions
    
    def _create_general_questions(self, text: str, key_concepts: List[str], num_questions: int, difficulty: str) -> List[Dict]:
        """Crea preguntas generales para cualquier tipo de texto"""
        questions = []
        
        # Pregunta sobre tema principal
        if len(questions) < num_questions:
            question = {
                "id": len(questions) + 1,
                "question": "¬øCu√°l es el tema central del texto analizado?",
                "options": [
                    "El tema principal desarrollado a lo largo del contenido",
                    "Un tema secundario mencionado brevemente",
                    "Informaci√≥n no relacionada con el contenido",
                    "Datos estad√≠sticos sin contexto"
                ],
                "correct_answer": 0,
                "explanation": "El texto se centra en desarrollar un tema principal espec√≠fico con informaci√≥n detallada y coherente.",
                "difficulty": difficulty
            }
            questions.append(question)
        
        # Pregunta sobre conceptos clave
        if key_concepts and len(questions) < num_questions:
            concept = key_concepts[0] if key_concepts else "el concepto principal"
            question = {
                "id": len(questions) + 1,
                "question": f"¬øQu√© papel juega {concept} en el contexto del texto?",
                "options": [
                    f"{concept} es un elemento fundamental para la comprensi√≥n del tema",
                    f"{concept} se menciona solo de forma tangencial",
                    f"{concept} contradice la informaci√≥n principal",
                    f"{concept} no tiene relaci√≥n con el contenido"
                ],
                "correct_answer": 0,
                "explanation": f"{concept} representa un elemento clave que contribuye significativamente a la comprensi√≥n integral del tema tratado.",
                "difficulty": difficulty
            }
            questions.append(question)
        
        return questions
    
    def _create_contextual_question(self, question_id: int, text: str, concepts: List[str], difficulty: str) -> Dict:
        """Crea una pregunta contextual espec√≠fica del texto"""
        
        # Extraer primera oraci√≥n significativa
        sentences = re.split(r'[.!?]+', text)
        meaningful_sentences = [s.strip() for s in sentences if len(s.strip()) > 50]
        
        if meaningful_sentences:
            context_sentence = meaningful_sentences[0]
            
            return {
                "id": question_id,
                "question": "Seg√∫n la informaci√≥n presentada en el texto, ¬øcu√°l es la afirmaci√≥n m√°s precisa?",
                "options": [
                    context_sentence[:80] + "..." if len(context_sentence) > 80 else context_sentence,
                    "Una afirmaci√≥n contradictoria al contenido del texto",
                    "Informaci√≥n no respaldada por el contenido analizado",
                    "Datos irrelevantes para el tema principal"
                ],
                "correct_answer": 0,
                "explanation": "Esta informaci√≥n proviene directamente del texto analizado y representa fielmente el contenido y contexto presentado.",
                "difficulty": difficulty
            }
        
        # Pregunta de respaldo
        return {
            "id": question_id,
            "question": "¬øCu√°l es el enfoque principal del contenido analizado?",
            "options": [
                "Proporcionar informaci√≥n educativa estructurada sobre el tema central",
                "Presentar datos sin conexi√≥n tem√°tica",
                "Contradecir informaci√≥n previamente establecida",
                "Ofrecer entretenimiento sin valor educativo"
            ],
            "correct_answer": 0,
            "explanation": "El texto mantiene un enfoque educativo claro, proporcionando informaci√≥n estructurada y coherente sobre el tema principal.",
            "difficulty": difficulty
        }
    
    async def generate_feedback(self, score: int, total: int, 
                              incorrect_questions: List[int], concepts: List[str]) -> str:
        """Genera feedback educativo personalizado y constructivo"""
        
        percentage = (score / total) * 100
        
        # Determinar tipo de contenido basado en conceptos
        text_type = self._infer_type_from_concepts(concepts)
        
        # Crear feedback estructurado y motivador
        feedback = self._create_comprehensive_feedback(score, total, percentage, concepts, incorrect_questions, text_type)
        
        return feedback
    
    def _infer_type_from_concepts(self, concepts: List[str]) -> str:
        """Infiere el tipo de contenido basado en los conceptos"""
        if not concepts:
            return "general"
        
        concept_text = " ".join(concepts).lower()
        
        for text_type, patterns in self.text_patterns.items():
            for keyword in patterns["keywords"]:
                if keyword in concept_text:
                    return text_type
        
        return "general"
    
    def _create_comprehensive_feedback(self, score: int, total: int, percentage: float, 
                                     concepts: List[str], incorrect_questions: List[int], text_type: str) -> str:
        """Crea feedback comprehensivo y personalizado"""
        
        # Encabezado motivacional seg√∫n rendimiento
        if percentage >= 90:
            header = "üéâ **¬°RENDIMIENTO EXCEPCIONAL!**"
            emoji = "üèÜ"
        elif percentage >= 80:
            header = "‚ú® **¬°EXCELENTE TRABAJO!**"
            emoji = "üåü"
        elif percentage >= 70:
            header = "üëç **¬°BUEN DESEMPE√ëO!**"
            emoji = "üìà"
        elif percentage >= 60:
            header = "üí™ **¬°PROGRESO POSITIVO!**"
            emoji = "üéØ"
        else:
            header = "üå± **¬°OPORTUNIDAD DE CRECIMIENTO!**"
            emoji = "üìö"
        
        feedback = f"{header}\n\n"
        
        # Resultado num√©rico destacado
        feedback += f"{emoji} **RESULTADO:** {score}/{total} respuestas correctas (**{percentage:.1f}%**)\n\n"
        
        # An√°lisis detallado por rango de rendimiento
        if percentage >= 90:
            feedback += self._create_excellent_feedback(concepts, text_type)
        elif percentage >= 70:
            feedback += self._create_good_feedback(concepts, incorrect_questions, text_type)
        elif percentage >= 50:
            feedback += self._create_improvement_feedback(concepts, text_type)
        else:
            feedback += self._create_foundational_feedback(concepts, text_type)
        
        # Agregar recomendaciones espec√≠ficas por tipo de contenido
        feedback += self._add_content_specific_recommendations(text_type, percentage)
        
        return feedback
    
    def _create_excellent_feedback(self, concepts: List[str], text_type: str) -> str:
        """Feedback para rendimiento excepcional"""
        feedback = ("üîç **AN√ÅLISIS DE RENDIMIENTO:**\n"
                   "Has demostrado un dominio sobresaliente del tema. Tu comprensi√≥n "
                   "de los conceptos clave es s√≥lida y tu capacidad de an√°lisis es ejemplar.\n\n")
        
        if concepts:
            feedback += f"üíé **FORTALEZAS IDENTIFICADAS:**\n"
            feedback += f"‚Ä¢ Excelente manejo de {concepts[0]}\n"
            if len(concepts) > 1:
                feedback += f"‚Ä¢ Comprensi√≥n avanzada de {concepts[1]}\n"
            feedback += "‚Ä¢ Capacidad de s√≠ntesis y an√°lisis cr√≠tico\n\n"
        
        feedback += ("üöÄ **PR√ìXIMOS DESAF√çOS:**\n"
                    "‚Ä¢ Explora aspectos m√°s profundos del tema\n"
                    "‚Ä¢ Busca conexiones con temas relacionados\n"
                    "‚Ä¢ Comparte tu conocimiento con otros estudiantes\n\n")
        
        return feedback
    
    def _create_good_feedback(self, concepts: List[str], incorrect_questions: List[int], text_type: str) -> str:
        """Feedback para buen rendimiento"""
        feedback = ("üîç **AN√ÅLISIS DE RENDIMIENTO:**\n"
                   "Tienes una base s√≥lida de conocimientos. Has captado los conceptos "
                   "principales, aunque hay algunas √°reas espec√≠ficas que puedes pulir.\n\n")
        
        if incorrect_questions:
            feedback += f"üìä **√ÅREAS DE OPORTUNIDAD:**\n"
            feedback += f"‚Ä¢ Revisar preguntas {', '.join(map(str, incorrect_questions[:3]))}\n"
            if concepts:
                feedback += f"‚Ä¢ Profundizar en {concepts[-1] if len(concepts) > 1 else concepts[0]}\n"
            feedback += "\n"
        
        feedback += ("üí° **ESTRATEGIAS DE MEJORA:**\n"
                    "‚Ä¢ Repasa los conceptos donde tuviste dificultades\n"
                    "‚Ä¢ Busca ejemplos adicionales de los temas complejos\n"
                    "‚Ä¢ Practica con ejercicios similares\n\n")
        
        return feedback
    
    def _create_improvement_feedback(self, concepts: List[str], text_type: str) -> str:
        """Feedback para rendimiento que necesita mejora"""
        feedback = ("üîç **AN√ÅLISIS DE RENDIMIENTO:**\n"
                   "Est√°s construyendo una base de conocimientos s√≥lida. Cada respuesta "
                   "correcta representa progreso real en tu comprensi√≥n del tema.\n\n")
        
        if concepts:
            feedback += f"üéØ **ENFOQUE RECOMENDADO:**\n"
            feedback += f"‚Ä¢ Refuerza los fundamentos de {concepts[0]}\n"
            if len(concepts) > 1:
                feedback += f"‚Ä¢ Practica m√°s con {concepts[1]}\n"
            feedback += "\n"
        
        feedback += ("üìñ **PLAN DE ESTUDIO:**\n"
                    "‚Ä¢ Dedica tiempo a comprender los conceptos b√°sicos\n"
                    "‚Ä¢ Utiliza recursos adicionales como videos o diagramas\n"
                    "‚Ä¢ Practica con ejercicios de dificultad gradual\n\n")
        
        return feedback
    
    def _create_foundational_feedback(self, concepts: List[str], text_type: str) -> str:
        """Feedback para rendimiento que necesita refuerzo fundamental"""
        feedback = ("üîç **AN√ÅLISIS DE RENDIMIENTO:**\n"
                   "Est√°s en proceso de construcci√≥n de conocimientos fundamentales. "
                   "No te desanimes, cada intento es una oportunidad valiosa de aprendizaje.\n\n")
        
        if concepts:
            feedback += f"üéØ **ENFOQUE FUNDAMENTAL:**\n"
            feedback += f"‚Ä¢ Comienza con los conceptos b√°sicos de {concepts[0]}\n"
            feedback += f"‚Ä¢ Dedica tiempo extra a entender definiciones clave\n\n"
        
        feedback += ("üìñ **ESTRATEGIA DE APRENDIZAJE:**\n"
                    "‚Ä¢ Estudia un concepto a la vez hasta dominarlo\n"
                    "‚Ä¢ Usa analog√≠as y ejemplos cotidianos\n"
                    "‚Ä¢ Practica con ejercicios muy b√°sicos primero\n"
                    "‚Ä¢ Busca ayuda cuando la necesites\n\n")
        
        feedback += ("üåü **MENSAJE MOTIVACIONAL:**\n"
                    "El aprendizaje es un proceso gradual y personal. Cada paso que das "
                    "te acerca m√°s al dominio del tema. Tu perseverancia es clave para el √©xito.\n\n")
        
        return feedback
    
    def _add_content_specific_recommendations(self, text_type: str, percentage: float) -> str:
        """Agrega recomendaciones espec√≠ficas seg√∫n el tipo de contenido"""
        
        recommendations = "üéì **RECOMENDACIONES ESPEC√çFICAS:**\n"
        
        if text_type == "historia":
            if percentage >= 80:
                recommendations += ("‚Ä¢ Explora fuentes primarias del per√≠odo estudiado\n"
                                  "‚Ä¢ Analiza diferentes perspectivas hist√≥ricas\n"
                                  "‚Ä¢ Conecta eventos con consecuencias a largo plazo\n")
            else:
                recommendations += ("‚Ä¢ Crea l√≠neas de tiempo para organizar eventos\n"
                                  "‚Ä¢ Estudia mapas hist√≥ricos del per√≠odo\n"
                                  "‚Ä¢ Memoriza fechas clave y personajes importantes\n")
        
        elif text_type == "ciencia":
            if percentage >= 80:
                recommendations += ("‚Ä¢ Busca aplicaciones pr√°cticas de los conceptos\n"
                                  "‚Ä¢ Realiza experimentos relacionados si es posible\n"
                                  "‚Ä¢ Investiga avances recientes en el √°rea\n")
            else:
                recommendations += ("‚Ä¢ Repasa las leyes y principios fundamentales\n"
                                  "‚Ä¢ Practica con diagramas y esquemas\n"
                                  "‚Ä¢ Relaciona conceptos con ejemplos cotidianos\n")
        
        elif text_type == "tecnolog√≠a":
            if percentage >= 80:
                recommendations += ("‚Ä¢ Experimenta con herramientas relacionadas\n"
                                  "‚Ä¢ Sigue las tendencias tecnol√≥gicas actuales\n"
                                  "‚Ä¢ Considera aplicaciones innovadoras\n")
            else:
                recommendations += ("‚Ä¢ Familiar√≠zate con la terminolog√≠a b√°sica\n"
                                  "‚Ä¢ Comprende los fundamentos antes de avanzar\n"
                                  "‚Ä¢ Practica con ejemplos step-by-step\n")
        
        else:
            recommendations += ("‚Ä¢ Refuerza la comprensi√≥n lectora\n"
                              "‚Ä¢ Practica el an√°lisis de textos similares\n"
                              "‚Ä¢ Desarrolla t√©cnicas de estudio efectivas\n")
        
        return recommendations
    
    def get_model_status(self) -> Dict[str, Any]:
        """Obtiene el estado completo de todos los modelos mejorados"""
        
        status = {
            "base_models": {
                "summarizer_loaded": self.summarizer is not None,
                "t5_model_loaded": self.t5_model is not None,
                "classifier_loaded": self.classifier is not None
            },
            "enhanced_models": {
                "enhanced_summarizer": hasattr(self, 'enhanced_summarizer'),
                "enhanced_generator": hasattr(self, 'enhanced_generator')
            },
            "fine_tuned_models": {
                "summarizer_loaded": "summarizer" in self.fine_tuned_models,
                "question_gen_loaded": "question_generator" in self.fine_tuned_models,
                "feedback_gen_loaded": "feedback_generator" in self.fine_tuned_models
            },
            "universal_patterns": {
                "text_types_supported": list(self.text_patterns.keys()),
                "pattern_count": len(self.text_patterns)
            },
            "device": self.device,
            "model_config_loaded": self.model_config is not None,
            "enhanced_features": True,
            "universal_text_support": True
        }
        
        if self.model_config:
            status["training_info"] = self.model_config.get("training_info", {})
        
        return status